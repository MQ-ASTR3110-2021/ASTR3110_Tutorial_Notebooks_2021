{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASTR3110 Tutorial 4: MCMC and Bayesian Reasoning\n",
    "\n",
    "Tutorial 4 of the *'Data Science Techniques in Astrophysics'* course at Macquarie University.\n",
    "\n",
    "## Learning outcomes from this tutorial\n",
    "\n",
    " * Understand what a sampler achieves\n",
    " * Understand the terms in Bayes's Formula and how they relate to fitting models\n",
    " * Use a MCMC sampler to fit a polynomial model to a simple 1D spectrum\n",
    " * Create a triangle plot to show correlations between parameters\n",
    " * Extract best-fit and uncertainty estimates from an MCMC chain\n",
    " * Apply the Nested Sampling algorithm to the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood and Priors\n",
    "\n",
    "In Tutorial 3 we used $\\chi^2_{\\rm model}$ difference between the model and data as a measure of *goodness of fit* and found the best-fitting model by minimizing its value. However, we often have *prior* independent measurements of the parameters we want to fit. We want this prior information to weight the total $\\chi^2$ value so that it prefers parameter values closer to our previous measurements. Each prior parameter estimate contributes its own $\\chi^2$ value. For example, for a parameter $p = p_{\\rm prior} \\pm \\sigma_{\\rm prior}$, the $\\chi^2_{\\rm prior}$ value is given by:\n",
    "\n",
    "$$\\chi^2_{\\rm prior} = \\left(\\frac{p_{\\rm model} - p_{\\rm prior}}{\\sigma_{\\rm prior}}\\right)^2$$.\n",
    "\n",
    "The total $\\chi^2$ value is then given by the sum of all values: $\\chi^2 = \\chi^2_{\\rm model} + \\chi^2_{\\rm prior}$.\n",
    "\n",
    "The *likelihood* is a related way of assessing a model fit: *what is the probability, or likelhood $\\mathcal{L}$, of getting the observed data given particular values of parameters p?* For Gaussian distributed likelihoods the likelihood is related to $\\chi^2$ via\n",
    "\n",
    "$$\\mathcal{L} = exp(-\\chi^2\\big/2)~~~~or~~~~-2 {\\rm ln}\\mathcal{L} = \\chi^2$$\n",
    "\n",
    "So that $\\chi^2$ is often referred to as the 'log-likelihood'. Because $\\mathcal{L}$ is in log-space, prior likelihoods are *multiplied* to get the total $\\mathcal{L}$. From a numerical perspective, the log-likelihood is also a smaller number and less likely to run into computational limits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for Google Drive and data access\n",
    "\n",
    "As with the tutorial last week, we will be operating on actual data, so please mount your Gooogle Drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment out if running locally\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into the correct directory\n",
    "#cd gdrive/'My Drive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be processing the same polarised radio-wavelength spectrum as last week. If you haven't already downloaded it, you can get it from this link: [HotSpot.dat](https://github.com/MQ-ASTR3110-2020/ASTR3110_Tutorial_Notebooks/blob/master/DATA/HotSpot.dat). Save this file to your Google Drive under, for example, your 'DATA/' directory.\n",
    "\n",
    "As a reminder, the file contains 7 columns corresponding to:\n",
    "\n",
    "[frequency_GHz, I_mJy, Q_mJy, U_mJy, dI_mJy, dQ_mJy, dU_mJy]\n",
    "\n",
    "and we want to access the columns [0] frequency, [1] flux and [4] uncertainty in flux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array has shape (columns, rows): (7, 198)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Read all columns into an Numpy array\n",
    "specArr  = np.loadtxt(\"DATA/HotSpot.dat\", dtype=\"float64\", unpack=True)\n",
    "\n",
    "# Convert Hz to GHz\n",
    "specArr[0] /= 1e9\n",
    "print(\"Array has shape (columns, rows):\", specArr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
